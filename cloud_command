cloud


[AWS]
KEY=AKIAQM5PKG2LN2JKRLHR
SECRET=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

[DWH]
DWH_CLUSTER_TYPE=single-node
DWH_NUM_NODES=1
DWH_NODE_TYPE=dc2.large
DWH_CLUSTER_IDENTIFIER=my-first-redshift
DWH_DB=myfirstdb
DWH_DB_USER=awsuser
DWH_DB_PASSWORD=Sahil1234
DWH_PORT=5439
DWH_IAM_ROLE_NAME=redshift-s3-access



KEY			= config.get('AWS','KEY')
SECRET			= config.get('AWS','SECRET')

DWH_CLUSTER_TYPE	= config.get('DWH','DWH_CLUSTER_TYPE')
DWH_NUM_NODES		= config.get('DWH','DWH_NUM_NODES')
DWH_NODE_TYPE		= config.get('DWH','DWH_NODE_TYPE')

DWH_CLUSTER_IDENTIFIER  = config.get('DWH','DWH_CLUSTER_IDENTIFIER')
DWH_DB			= config.get('DWH','DWH_DB')
DWH_DB_USER		= config.get('DWH','DWH_DB_USER')
DWH_DB_PASSWORD		= config.get('DWH','DWH_DB_PASSWORD')
DWH_PORT		= config.get('DWH','DWH_PORT')

DWH_IAM_ROLE_NAME	= config.get('DWH','DWH_IAM_ROLE_NAME')

(DWH_DB_USER,DWH_DB_PASSWORD,DWH_DB)



pd.DataFrame({"param":['DWH_CLUSTER_TYPE','DWH_NUM_NODES','DWH_NODE_TYPE','DWH_CLUSTER_IDENTIFIER','DWH_DB','DWH_DB_USER','DWH_DB_PASSWORD','DWH_PORT','DWH_IAM_ROLE_NAME'],
value:[DWH_CLUSTER_TYPE,DWH_NUM_NODES,DWH_NODE_TYPE,DWH_CLUSTER_IDENTIFIER,DWH_DB,DWH_DB_USER,DWH_DB_PASSWORD,DWH_PORT,DWH_IAM_ROLE_NAME]
})


ec2=boto3.resource('ec2',region_name='ap-south-1',aws_access_key_id=KEY,aws_secret_access_key=SECRET)

bucket=s3.Bucket('vishnu-test-buck')
log_data_files=[filename.key for filename in bucket.objects.filter(Prefix='')]
log_data_files


roleArn=iam.get_role(RoleName=DWH_IAM_ROLE_NAME)['Role']['Arn']

#creating cluster in redshift
try:
	response=redshift.create_cluster(
	ClusterType=DWH_CLUSTER_TYPE,
	NodeType=DWH_NODE_TYPE,

	#identifier & credentials
	DBName=DWH_DB,
	ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,
	MasterUsername=DWH_DB_USER,
	MasterUserPassword=DWH_DB_PASSWORD,

	#Roles (for s3 access)
	IamRoles=[roleArn]
	)
except Exceptionas as e:
	print(e)


redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)


def prettyRedshiftProps(props):
	pd.set_option('display.max_colwidth',-1)
	KeysToShow=['ClusterIdentifier','NodeType','CluserStatus','MasterUsername','DBName','Endpoint','VpcId']
	x=[(k,v) for k,v in props.items() if k in  KeysToShow]
	return pd.DataFrame(data=x,columns=['Key','value'])

myClusterprops=redshift.describe_clusters(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER)['Clusters'][0]
prettyRedshiftProps(myClusterProps)


DWH_ENDPOINT=myClusterProps['Endpoint']['Address']
DWH_ROLE_ARN=myClusterProps['IamRoles'][0]['IamRoleArn']
DB_NAME=myClusterProps['DBName']
DB_USER=myClusterProps['MasterUsername']

try:
	vpc=ec2.Vpc(id=myClusterProps['VpcId'])
	defaultSg=list(vpc.security_groups.all())[0]
	print(defaultSg)

	defaultSg.authorize_ingress(
		GroupName=defaultSg.group_name,
		CidrIp='0.0.0.0/0',
		IpProtocol='TCP',
		FromPort=int(DWH_PORT),
		ToPort=int(DWH_PORT)
	)

except Exception as e:
		print(e)


try:
	conn=psycopg2.connect(host=DWH_ENDPOINT,dbname=DB_NAME,user=DB_USER,password='Sahil1234',port=5439)
except psycopg2.Error as e:
	print('Error could not take connection to the progress database')
	print(e)

conn.set_session(autocommit=True)

try:
	cur=conn.cursor()
except psycopg2.Error as e:
	print('Error: Could not get cursor to the Database')
	print(e)


try:
	cur.execute(""" create table users(
	userid integer not null distkey sortkey,
	username char(8),
	firstname varchar(30),
	lastname varchar(30),
	city varchar(30),
	state char (2),
	email varchar(100),
	phone char(14),
	likesports boolean,
	liketheatre boolean,
	likeconcerts boolean,
	likejazz boolean,
	likeclassical boolean,
	likeopera boolean,
	likerock boolean,
	likevegas boolean,
	likebroadway boolean,
	likemusicals boolean);""")
except psycopg2.Error as e:
	print('Error:Issue creating table')
	print(e)



try:
	cur.execute(""" create table venue(
	venueid smallint not null distkey sortkey,
	venuename varchar(100),
	venuecity varchar(30),
	venuestate varchar(30),
	venueseats integer);""")
except psycopg2.Error as e:
	print('Error:Issue creating table')

	print(e)


try:
	cur.execute(""" create table category(
	catid smallint not null distkey sortkey,
	catgroup varchar(10),
	catname varchar(10),
	catdesc varchar(50));

create table date(
	dateid smallint not null distkey sortkey,
	caldate date not null,
	day character(3) not null,
	week smallint not null,
	month character(5) not null,
	qtr character(5) not null,
	year smallint not null,
	holiday boolean default('N'));

create table event(
	eventid integer not null distkey,
	venueid smallint not null,
	catid smallint not null,
	dateid smallint not null sortkey,
	eventname varchar(200),
	starttime timestamp);


create table listing(
	listid integer not null distkey,
	sellerid integer not null,
	eventid integer not null,
	dateid smallint not null sortkey,
	numtickets smallint not null,
	priceperticket decimal(8,2),
	totalprice decimal(8,2),
	listtime timestamp);

	""")
except psycopg2.Error as e:
	print('Error:Issue creating table')
	print(e)


#now loading data from s3 to redshift

try:
	cur.execute("""
	copy users from 's3://vishnu-test-buck/allusers_pipe.txt'
	credentials 'aws_iam_role=arn:aws:iam::027748087446:role/redshift-s3-access'
	delimiter '|'
	region 'ap-south-1'
	""")
except psycopg2.Error as e:
	print("Error: Issue crerating table")
	print(e)


#now loading data from s3 to redshift
# for users table
try:
	cur.execute("""
	copy venue from 's3://vishnu-test-buck/venue_pipe.txt'
	credentials 'aws_iam_role=arn:aws:iam::027748087446:role/redshift-s3-access'
	delimiter '|'
	region 'ap-south-1'
	""")
except psycopg2.Error as e:
	print("Error: Issue crerating table")
	print(e)



#now loading data from s3 to redshift
# for category table
try:
	cur.execute("""
	copy category from 's3://vishnu-test-buck/category_pipe.txt'
	credentials 'aws_iam_role=arn:aws:iam::027748087446:role/redshift-s3-access'
	delimiter '|'
	region 'ap-south-1'
	""")
except psycopg2.Error as e:
	print("Error: Issue crerating table")
	print(e)



#now loading data from s3 to redshift
# for date table
try:
	cur.execute("""
	copy date from 's3://vishnu-test-buck/date2008_pipe.txt'
	credentials 'aws_iam_role=arn:aws:iam::027748087446:role/redshift-s3-access'
	delimiter '|'
	region 'ap-south-1'
	""")
except psycopg2.Error as e:
	print("Error: Issue crerating table")
	print(e)


#now loading data from s3 to redshift
# for event table
try:
	cur.execute("""
	copy event from 's3://vishnu-test-buck/allevents_pipe.txt'
	credentials 'aws_iam_role=arn:aws:iam::027748087446:role/redshift-s3-access'
	delimiter '|'
	region 'ap-south-1'
	""")
except psycopg2.Error as e:
	print("Error: Issue crerating table")
	print(e)


#now loading data from s3 to redshift
# for listing table
try:
	cur.execute("""
	copy listing from 's3://vishnu-test-buck/listings_pipe.txt'
	credentials 'aws_iam_role=arn:aws:iam::027748087446:role/redshift-s3-access'
	delimiter '|'
	region 'ap-south-1'
	""")
except psycopg2.Error as e:
	print("Error: Issue crerating table")
	print(e)


#deleting cluster

redshift.delete_cluster(ClusterIdentifier=DWH_CLUSTER_IDENTIFIER,SkipFinalClusterSnapshot=TRUE)

